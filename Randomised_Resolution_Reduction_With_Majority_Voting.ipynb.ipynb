{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load basic dependencies:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Disable TensorFlow eager execution:\n",
    "import tensorflow as tf\n",
    "if tf.executing_eagerly():\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Load Keras dependencies:\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load ART dependencies:\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.preprocessing.preprocessing import Preprocessor\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from art.attacks.evasion import PixelAttack, TargetedUniversalPerturbation\n",
    "from art.utils import to_categorical\n",
    "\n",
    "# Install ImageNet stubs:\n",
    "!{sys.executable} -m pip install git+https://github.com/nottombrown/imagenet_stubs\n",
    "!{sys.executable} -m pip install kaggle\n",
    "import imagenet_stubs\n",
    "from imagenet_stubs.imagenet_2012_labels import name_to_label, label_to_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab3b25-a03a-45ff-bc6f-cf15662ba281",
   "metadata": {},
   "source": [
    "To use the Kaggle API, sign up for a Kaggle account at https://www.kaggle.com. Then go to the 'Account' tab of your user profile (https://www.kaggle.com/<username>/account) and select 'Create API Token'. This will trigger the download of kaggle.json, a file containing your API credentials. Place this file in the location ~/.kaggle/kaggle.json (on Windows in the location C:\\\\Users\\\\<Windows-username>\\\\.kaggle\\\\kaggle.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e08cf0-5653-43be-9f3c-461352e72b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d priyerana/imagenet-10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ade90f-31a6-4e86-b7a7-6ac4d7797832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Either use the following command to unzip followed by remove the compressed file, or you can do it manually. Specify the paths accordingly in the next steps.\n",
    "!unzip imagenet-10k.zip && rm imagenet-10k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374beee-c48d-4ef4-ae21-bbc49231777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the labels file\\\n",
    "!kaggle competitions download imagenet-object-localization-challenge -f LOC_synset_mapping.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc0b3d-0786-4d00-9625-0b0ca785a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving all images to a single folder for easier access.\n",
    "!mv imagenet_subtrain/*/* imagenet_subtrain/ && rmdir imagenet_subtrain/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b5661-915a-41ed-9659-22d98420a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "!readlink -f imagenet_subtrain/* > imagepaths.txt\n",
    "with open('imagepaths.txt', 'r') as text:\n",
    "    imagepaths = text.read()[:-1].split('\\n')\n",
    "!rm imagepaths.txt\n",
    "with open('LOC_synset_mapping.txt','r') as text:\n",
    "    imagelabels= text.read()[:-1].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207e2f6-5b66-429f-96b1-1b5cc1b7fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_labels=list()\n",
    "for i in imagepaths:\n",
    "    for j in imagelabels:\n",
    "        if i[i.rfind('/')+1:i.rfind('_')]==j[:j.find(' ')]:\n",
    "            image_labels.append(name_to_label(j[j.find(' ')+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = list()\n",
    "for image_path in imagepaths:\n",
    "    im = image.load_img(image_path, target_size=(224, 224))\n",
    "    im = image.img_to_array(im)\n",
    "    images_list.append(im)\n",
    "images = np.array(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of images:', images.shape[0])\n",
    "print('Dimension of images:', images.shape[1], 'x', images.shape[2], 'pixels')\n",
    "print('Number of color channels:', images.shape[3], '(RGB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32739f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8)); plt.imshow(images[97] / 255); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2ab8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print('label', i, '-', label_to_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb67988",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_art = np.expand_dims(images[idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a194b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ffed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Preprocessor(Preprocessor):\n",
    "\n",
    "    def __call__(self, x, y=None):\n",
    "        return preprocess_input(x.copy()), y\n",
    "\n",
    "    def estimate_gradient(self, x, gradient):\n",
    "        return gradient[..., ::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9974831",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ResNet50Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432583df",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalclassifier=KerasClassifier(model,clip_values=(0, 255), preprocessing=preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_resolution(img, resolution_percentage):\n",
    "    # Extract the height, width, and channels from the input array\n",
    "    height, width, channels = img.shape[1:]\n",
    "    # Calculate the new height and width based on the input resolution percentage\n",
    "    new_height = int(height * resolution_percentage / 100)\n",
    "    new_width = int(width * resolution_percentage / 100)\n",
    "    # Resize the image\n",
    "    img_resized = cv2.resize(img[0], (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    # Resize back to original size\n",
    "    img_resized_back = cv2.resize(img_resized, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    # Reshape the output to match the input shape\n",
    "    img_resized_back = np.expand_dims(img_resized_back, axis=0)\n",
    "    return img_resized_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93e38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterClassifierWithoutRandom(KerasClassifier):\n",
    "        \n",
    "    def predict(\n",
    "        self, x: np.ndarray, batch_size: int = 128, training_mode: bool = False, **kwargs\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Perform prediction for a batch of inputs.\n",
    "\n",
    "        :param x: Input samples.\n",
    "        :param batch_size: Size of batches.\n",
    "        :param training_mode: `True` for model set to training mode and `'False` for model set to evaluation mode.\n",
    "        :return: Array of predictions of shape `(nb_inputs, nb_classes)`.\n",
    "        \"\"\"\n",
    "        # Apply preprocessing\n",
    "        x_preprocessed, _ = self._apply_preprocessing(x, y=None, fit=False)\n",
    "\n",
    "        # Create containers for our predictions and spatial smoothening window sizes\n",
    "        prediction_labels=[]\n",
    "        prediction_scores=[]\n",
    "        label_counts={}\n",
    "        smoothening_values=[99,97,95,93,91,89,87,85,83,81]\n",
    "        \n",
    "        #Predict with each window size, and store the labels and prediction scores in their containers\n",
    "        for i in smoothening_values:\n",
    "            x_def=reduce_resolution(img=x_preprocessed,resolution_percentage=i)\n",
    "            pred = self._model.predict(x_def,batch_size=batch_size)\n",
    "            label = label_to_name(np.argmax(pred, axis=1)[0])\n",
    "            prediction_scores.append(pred)\n",
    "            prediction_labels.append(label)\n",
    "        \n",
    "        #finding out which label is most frequently identified, and taking a weighted mean of that label's scores\n",
    "        for label in prediction_labels:\n",
    "            if label in label_counts:\n",
    "                label_counts[label] += 1\n",
    "            else:\n",
    "                label_counts[label] = 1\n",
    "                \n",
    "        most_frequent_label = max(label_counts, key=label_counts.get)\n",
    "        most_frequent_indexes = [i for i, p in enumerate(prediction_labels) if p == most_frequent_label]\n",
    "        most_frequent_pred_scores = [prediction_scores[i] for i in most_frequent_indexes]\n",
    "\n",
    "        weights = 1/np.array([smoothening_values[i] for i in most_frequent_indexes])\n",
    "        predictions = np.average(most_frequent_pred_scores,axis=0,weights=weights)\n",
    "        \n",
    "        # Apply postprocessing\n",
    "        predictions = self._apply_postprocessing(preds=predictions, fit=False)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe83784",
   "metadata": {},
   "outputs": [],
   "source": [
    "betterclassifierwithoutrandom = BetterClassifierWithoutRandom(model,clip_values=(0, 255), preprocessing=preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1467ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterClassifier(KerasClassifier):\n",
    "        \n",
    "    def predict(\n",
    "        self, x: np.ndarray, batch_size: int = 128, training_mode: bool = False, **kwargs\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Perform prediction for a batch of inputs.\n",
    "\n",
    "        :param x: Input samples.\n",
    "        :param batch_size: Size of batches.\n",
    "        :param training_mode: `True` for model set to training mode and `'False` for model set to evaluation mode.\n",
    "        :return: Array of predictions of shape `(nb_inputs, nb_classes)`.\n",
    "        \"\"\"\n",
    "        # Apply preprocessing\n",
    "        x_preprocessed, _ = self._apply_preprocessing(x, y=None, fit=False)\n",
    "\n",
    "        # Create containers for our predictions and spatial smoothening window sizes\n",
    "        prediction_labels=[]\n",
    "        prediction_scores=[]\n",
    "        label_counts={}\n",
    "        smoothening_values=[np.random.randint(70,99) for i in range(10)]\n",
    "        \n",
    "        #Predict with each window size, and store the labels and prediction scores in their containers\n",
    "        for i in smoothening_values:\n",
    "            x_def=reduce_resolution(img=x_preprocessed,resolution_percentage=i)\n",
    "            pred = self._model.predict(x_def,batch_size=batch_size)\n",
    "            label = label_to_name(np.argmax(pred, axis=1)[0])\n",
    "            prediction_scores.append(pred)\n",
    "            prediction_labels.append(label)\n",
    "        \n",
    "        #finding out which label is most frequently identified, and taking a weighted mean of that label's scores\n",
    "        for label in prediction_labels:\n",
    "            if label in label_counts:\n",
    "                label_counts[label] += 1\n",
    "            else:\n",
    "                label_counts[label] = 1\n",
    "                \n",
    "        most_frequent_label = max(label_counts, key=label_counts.get)\n",
    "        most_frequent_indexes = [i for i, p in enumerate(prediction_labels) if p == most_frequent_label]\n",
    "        most_frequent_pred_scores = [prediction_scores[i] for i in most_frequent_indexes]\n",
    "\n",
    "        weights = 1/np.array([smoothening_values[i] for i in most_frequent_indexes])\n",
    "        predictions = np.average(most_frequent_pred_scores,axis=0,weights=weights)\n",
    "        \n",
    "        # Apply postprocessing\n",
    "        predictions = self._apply_postprocessing(preds=predictions, fit=False)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "betterclassifier = BetterClassifier(model,clip_values=(0, 255), preprocessing=preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f08761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack1=ProjectedGradientDescent(normalclassifier, targeted=True, max_iter=40, eps_step=1, eps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack2=ProjectedGradientDescent(betterclassifierwithoutrandom, targeted=True, max_iter=40, eps_step=1, eps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f462fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack3=ProjectedGradientDescent(betterclassifier, targeted=True, max_iter=40, eps_step=1, eps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30324692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(attack1,attack2,attack3,imageset):\n",
    "    totaltime=time.time()\n",
    "    file=open('testresult.csv', 'a', newline='')\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['INPUT_IMG','NORM_CLAS_ORIG_IMG','NCOI_CONF','NCOI_RSLT','NCOI_TIME','NORM_CLAS_ADV_IMG','NCAI_CONF','NCAI_L_0','NCAI_L_1','NCAI_L_2','NCAI_L_INF','NCAI_RSLT','NCAI_TIME','BET_CLAS_NO_RAND_OG_IMG','BCNROI_CONF','BCNROI_RSLT','BCNROI_TIME','BET_CLAS_NO_RAND_ADV_IMG','BCNRAI_CONF','BCNRAI_L_0','BCNRAI_L_1','BCNRAI_L_2','BCNRAI_L_INF','BCNRAI_RSLT','BCNRAI_TIME','BET_CLAS_OG_IMG','BCOI_CONF','BCOI_RSLT','BCOI_TIME','BET_CLAS_ADV_IMG','BCAI_CONF','BCAI_L_0','BCAI_L_1','BCAI_L_2','BCAI_L_INF','BCAI_RSLT','BCAI_TIME'])\n",
    "\n",
    "    for i,image_label in enumerate(imageset):\n",
    "        x_art = np.expand_dims(imageset[i], axis=0)\n",
    "        \n",
    "        #normal classifier on original image\n",
    "        time1_1=time.time()\n",
    "        pred1_1=normalclassifier.predict(x_art)\n",
    "        time1_1=time.time() - time1_1\n",
    "        label1_1=np.argmax(pred1_1,axis=1)[0]\n",
    "        confidence1_1=pred1_1[:,label1_1][0]\n",
    "        if image_labels[i] == label1_1:\n",
    "            result1_1=1\n",
    "        elif target_label == label1_1:\n",
    "            result1_1=-1\n",
    "        else: result1_1=0\n",
    "        \n",
    "        #normal classifier on adversarial image\n",
    "        x_art_adv1 = attack1.generate(x_art,y=to_categorical([target_label]))\n",
    "        time1_2=time.time()\n",
    "        pred1_2=normalclassifier.predict(x_art_adv1)\n",
    "        time1_2=time.time() - time1_2\n",
    "        label1_2=np.argmax(pred1_2,axis=1)[0]\n",
    "        confidence1_2=pred1_2[:,label1_2][0]\n",
    "        l_0_1_2 = int(99*len(np.where(np.abs(x_art[0] - x_art_adv1[0])>0.5)[0]) / (224*224*3)) + 1   \n",
    "        l_1_1_2 = int(99*np.sum(np.abs(x_art[0] - x_art_adv1[0])) / np.sum(np.abs(x_art[0]))) + 1\n",
    "        l_2_1_2 = int(99*np.linalg.norm(x_art[0] - x_art_adv1[0]) / np.linalg.norm(x_art[0])) + 1 \n",
    "        l_inf_1_2 = int(99*np.max(np.abs(x_art[0] - x_art_adv1[0])) / 255) + 1\n",
    "        if image_labels[i] == label1_2:\n",
    "            result1_2=1\n",
    "        elif target_label == label1_2:\n",
    "            result1_2=-1\n",
    "        else: result1_2=0\n",
    "        \n",
    "        #better classifier without randomness on original image\n",
    "        time2_1=time.time()\n",
    "        pred2_1=betterclassifierwithoutrandom.predict(x_art)\n",
    "        time2_1=time.time() - time2_1\n",
    "        label2_1=np.argmax(pred2_1,axis=1)[0]\n",
    "        confidence2_1=pred2_1[:,label2_1][0]\n",
    "        if image_labels[i] == label2_1:\n",
    "            result2_1=1\n",
    "        elif target_label == label2_1:\n",
    "            result2_1=-1\n",
    "        else: result2_1=0\n",
    "        \n",
    "        #better classifier without randomness on adversarial image\n",
    "        x_art_adv2 = attack2.generate(x_art,y=to_categorical([target_label]))\n",
    "        time2_2=time.time()\n",
    "        pred2_2=betterclassifierwithoutrandom.predict(x_art_adv2)\n",
    "        time2_2=time.time() - time2_2\n",
    "        label2_2=np.argmax(pred2_2,axis=1)[0]\n",
    "        confidence2_2=pred2_2[:,label2_2][0]\n",
    "        l_0_2_2 = int(99*len(np.where(np.abs(x_art[0] - x_art_adv2[0])>0.5)[0]) / (224*224*3)) + 1   \n",
    "        l_1_2_2 = int(99*np.sum(np.abs(x_art[0] - x_art_adv2[0])) / np.sum(np.abs(x_art[0]))) + 1\n",
    "        l_2_2_2 = int(99*np.linalg.norm(x_art[0] - x_art_adv2[0]) / np.linalg.norm(x_art[0])) + 1 \n",
    "        l_inf_2_2 = int(99*np.max(np.abs(x_art[0] - x_art_adv2[0])) / 255) + 1\n",
    "        if image_labels[i] == label2_2:\n",
    "            result2_2=1\n",
    "        elif target_label == label2_2:\n",
    "            result2_2=-1\n",
    "        else: result2_2=0\n",
    "        \n",
    "        #better classifier on original image\n",
    "        time3_1=time.time()\n",
    "        pred3_1=np.mean([betterclassifier.predict(x_art) for _ in range(5)],axis=0)\n",
    "        time3_1=(time.time() - time3_1)/5\n",
    "        label3_1=np.argmax(pred3_1,axis=1)[0]\n",
    "        confidence3_1=pred3_1[:,label3_1][0]\n",
    "        if image_labels[i] == label3_1:\n",
    "            result3_1=1\n",
    "        elif target_label == label3_1:\n",
    "            result3_1=-1\n",
    "        else: result3_1=0\n",
    "        \n",
    "        #better classifier on adversarial image\n",
    "        x_art_adv3 = attack3.generate(x_art,y=to_categorical([target_label]))\n",
    "        time3_2=time.time()\n",
    "        pred3_2=np.mean([betterclassifier.predict(x_art_adv3) for _ in range(5)],axis=0)\n",
    "        time3_2=(time.time() - time3_2)/5\n",
    "        label3_2=np.argmax(pred3_2,axis=1)[0]\n",
    "        confidence3_2=pred3_2[:,label3_2][0]\n",
    "        l_0_3_2 = int(99*len(np.where(np.abs(x_art[0] - x_art_adv3[0])>0.5)[0]) / (224*224*3)) + 1   \n",
    "        l_1_3_2 = int(99*np.sum(np.abs(x_art[0] - x_art_adv3[0])) / np.sum(np.abs(x_art[0]))) + 1\n",
    "        l_2_3_2 = int(99*np.linalg.norm(x_art[0] - x_art_adv3[0]) / np.linalg.norm(x_art[0])) + 1 \n",
    "        l_inf_3_2 = int(99*np.max(np.abs(x_art[0] - x_art_adv3[0])) / 255) + 1\n",
    "        if image_labels[i] == label3_2:\n",
    "            result3_2=1\n",
    "        elif target_label == label3_2:\n",
    "            result3_2=-1\n",
    "        else: result3_2=0\n",
    "        \n",
    "        writer.writerow([image_labels[i],label1_1,'{0:.2f}'.format(confidence1_1),result1_1,time1_1,label1_2,'{0:.2f}'.format(confidence1_2),l_0_1_2,l_1_1_2,l_2_1_2,l_inf_1_2,result1_2,time1_2,label2_1,'{0:.2f}'.format(confidence2_1),result2_1,time2_1,label2_2,'{0:.2f}'.format(confidence2_2),l_0_2_2,l_1_2_2,l_2_2_2,l_inf_2_2,result2_2,time2_2,label3_1,'{0:.2f}'.format(confidence3_1),result3_1,time3_1,label3_2,'{0:.2f}'.format(confidence3_2),l_0_3_2,l_1_3_2,l_2_3_2,l_inf_3_2,result3_2,time3_2])\n",
    "        print(i)\n",
    "    totaltime=time.time() - totaltime\n",
    "    print('Total time taken for attack =',totaltime,'seconds')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(attack1,attack2,attack3,images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6bfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('testresult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34977a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
